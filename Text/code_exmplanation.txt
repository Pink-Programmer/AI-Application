def combine_data(trade_datas):

This function is used to merge different datasets. A list of DataFrames is passed, which are combined into one at the end. Since datasets from different companies is used in this project, it is necessary to merge them in a standardised way.

def modify_data(trade_data, t_previous_days, t_label_days):
This function is used to modify a data set. The purpose of modifying the data set is to extract more information from the given data set and use it as an additional feature. The new fetures are used, for example, to recognise temporal patterns. The label is also created in this function. 
To execute the functions, the dataset is required as well as the number of days immediately before and after the respective data point that are to be analysed

def plot_label_visualization(data):
With this function, two features are always compared graphically in the form of coordinate systems and entered data points. This makes it clear which of the features created play a major role in identifying the label or have no influence.

def plot_label_visualization(data):
This function displays the result of the automatically created labels. The progression of a price is displayed graphically. For each label, 3 data points are selected at random and displayed in the graph in the form of dots in different colours. A vertical line with the respective colour is then drawn for each data point, making it clear which point in time is being considered for a forecast. 


The following functions have been created to summarise all the individual steps involved in creating the respective models. The general procedure of the functions is very similar. To execute the function, a previously modified dataset is provided. Firstly, the dataset is split into test and training data. Then the model is created and trained with the training data. At the end, the trained model is tested with the test data and a value for the accuracy is created. At the end, the model, the predictions made during testing, the labels and the accuracy are returned.

def run_decision_tree_classifier_by_sklearn(modified_trade_data):
This function is about the creation of a decision tree classifier with the help of the module of the Skleran library. The following function by Sklearn is used: ....

def def run_random_forest_classifier_by_sklearn(modified_trade_data):
This function involves the creation of a random forest classifier with the help of the Skleran library module. The following function by SKlearn is used: ....

def run_decision_tree_from_scratch(modified_trade_data):
This function involves the creation of a decision tree classifier whose algorithm was implemented within the scope of this project. The exact algorithm will be explained in more detail later.

def def run_random_forest_from_scratch(modified_trade_data):
This function involves the creation of a random forest classifier whose algorithm was implemented within the scope of this project. The exact algorithm will be explained in more detail later.

class Tree_Node():
The class Tree_Node represents a Node in a Decision Tree. It contains information about the splitting of the tree including the feature index, a threshhold and a subtree. Additionally it contains the information gain resulting frim a splitting of a tree. Furthermore it contains the label if it is a leaf node.

class Decision tree():
The Decision_tree class represents a Decision tree classifier which is implemented from scratch in the puprose of this project. It contains the parameters like mind_datas_branching and max_depth which describe how often a tree will be splitted and the maximum depth of the split. Furthermore it contains the root of the previous branches.

def create_tree(self, dataset, curr_depth=0) 
The function create_tree builds a Decision Tree recursively based on the given dataset. It uses values like min_datas_branching and max_depth as conditional values to decide wether a conditions are met to calculate the best split and build another subtree recursively. If the conditions aren't met, a leaf node will be created.

def get_best_branching(self, dataset, number_of_datas, number_of_features):
This method searches for the best split in a decision tree based on the dataset. It iterates through the features and their possible thresholds to calculate the best branching. It calculates the potential threshold for every feature, devides the dataset and calculates the information gain using wether the gini index or the entropy. It updates the dictionary of the best branchings based on the most highest possible improvement in the information gain value.

def branch_tree(self, dataset, feature_index, threshold):
The function branch_tree devides a dataset based on a feature and a threshold. It creates two arrays in which the datas smaller or bigger then the treshholds are seperated.

def information_gain(self, parent, l_child, r_child, mode="entropy"):
The information_gain function is used to calculate the information gain after a splitting of a branch. For the calculation it uses ether the Gini index or the entropy, determined by the 'mode' parameter.

def entropy(self, y):   
With the entropy function, disorders and randomness within a set of labels can be calculated. By examinating the different types of labels and quantifying how unpredictabile they are, it calculates a probability.

def gini_index(self, y): 
With the function gini_index, similar like in the entropy funtion, the impurity or disorder is going to be mesured.By iterating through the labels, it calcultes the Gini index based on the probobilzy of the occurrence of each of the labels. After applying a specific mathematical formula, it returns the Gini index.

def calculate_leaf_value(self, label):
The funtion calculate_leaf_value detects the label of a leaf note. It predicts the value by doing a majority voting of the labels that the leaf contains. The most frequent label will be returned as it's label.

def fit(self, data, label):
Withe the fit function, the Decsion Tree is going to be trained. For this, the dataset and the labels are getting merched before using the function create_tree to establish the nodes.

def predict(self, data): 
The function predict is used to create predictions based on the given dataset. It iterates through each data point and creates a prediction with the funktion make_predictions function.

def make_prediction(self, x, tree):
The make_prediction function is used within the predict function. It uses the Decision Tree structure and evaluates a single data point against the nodes of the tree. It compares the feature values with the nodes and finds the correct root through the tree. Finally it finds the predicted label when reaching the leaf note and returns it.


____


class RandomForest:
The class RandomForest is used to build a Random Forest model. It is implemented from scratch and create decision trees that are, as described above, implemented in scratch as well. The RandomForest class uses parameters like n_trees to describe the number of trees within the decision forest. Furthermore it uses the parameters like max_depth and min_datas_branching which are necessary to create a decision tree. Furthermore it contains a parameter which describes the number of features in the dataset and another which contains all trees in an array.

def fit(self, X, y):
The Random Forest gets trained by the function fit. It creates multiple Decision Trees for the forest. When creating the Decision tree, it uses the functions that are explained in the Decision Tree class section. After the creation of the individual decision trees the function samples() is going to be used to create a diverse subsets for the input data of each tree. This way, the Random Forest model has a higher variability among a tree which leads to more robustness and a higher predictive performance.

def samples(self, X, y):
After each Decision tree is created, the function samples() creates different training datasets for each tree. These datasets are created randomly out of the given dataset. This way, unique training datasets are created which leads to an individual training of the trees.

def identify_most_common(self, y):
This function detects the most frequently occuring label within a set of labels. These labels are created by all of the Decision trees in the Random Forest. The most common label will be returned.

def predict(self, X):
With the predict() function, the created Random Forest model will be used to predict the label of a given test dataset. The data will run through all created Decision trees in the forest. Each Decision tree will predict the label of the data. Using the predictions of all trees, the most commen predicted label is going to be taken as the final predicted label.

______


def plot_roc(label, Y_test, Y_pred):
The function plot_roc() is used to plot the Receiver Operating Characteristic (ROC) curve. It is used to evaluate the model on it's quality. It takes the predicted and the true labels and calculates the false positive and and true positive rate. With these rates, the function will plot the ROC curve which will visualize the model's perfomrance.




